"""
Tests the methods for the OME-Zarr
conversion package
"""

import os
import tempfile
import unittest
from pathlib import Path
from typing import List, Optional, Tuple, Union

import dask
import numpy as np
import tifffile
import zarr
from parameterized import parameterized
from tests import params
from utils import utils
from zarr_converter import ZarrConverter

PathLike = Union[str, Path]


def _create_tiffs_files(
    path_to_tiffs: str, n_tiffs: int = 4, shape: Tuple[int] = (256, 256, 256)
):
    """
    Creates images for tests

    Parameters
    -------------
    path: PathLike
        Path where toy images are going to be stored

    n_tiffs: Optional[int]
        Number of tiffs per folder. Default: 4

    shape: Optional[Tuple[int]]
        Shape of each tiff image
    """
    for idx_tiffs in range(n_tiffs):
        tiff_data = np.ones(shape, dtype=np.uint16)
        tifffile.imwrite(
            os.path.join(path_to_tiffs, f"data_{idx_tiffs}.tif"), tiff_data
        )


def _create_multichannel_tiff_files(
    root: str,
    n_tiffs: int = 4,
    n_channels: int = 3,
    shape: Tuple[int] = (256, 256, 256),
):
    """
    Creates a dataset with a single/multiple channel(s)

    Parameters
    -------------
    root: str
        Root where the files will be stored

    n_tiffs: Optional[int]
        Number of tiffs per folder. Default: 4

    n_channels: Optional[int]
        Number of channels in the toy dataset

    shape: Optional[Tuple[int]]
        Shape of each tiff image
    """

    for channel_idx in range(n_channels):
        channel_path = Path(root).joinpath(f"channel_{channel_idx}/x/y/")
        utils.create_folder(channel_path)
        _create_tiffs_files(channel_path, n_tiffs=n_tiffs, shape=shape)


def _create_zarr_file(
    path_to_files: PathLike,
    output_path: PathLike,
    image_name: Optional[str] = "test_zarr_1.zarr",
    channels: Optional[List[str]] = None,
):
    """
    Function to create the zarr file

    Parameters
    ------------
    path_to_files: PathLike
        Path where the raw images are stored

    output_path: PathLike
        Path where the OME-Zarr image will be stored

    image_name: Optional[str]
        Image name for the OME-Zarr file.
        Default: test_zarr_1.zarr

    channels: Optional[List[str]]
        List with the channel names
    """
    test_writer = ZarrConverter(
        path_to_files, output_path, {"codec": "zstd", "clevel": 1}, channels
    )

    config = {
        "codec": "zstd",
        "clevel": 1,
        "scale_factor": [2, 2, 2],
        "pyramid_levels": 5,
    }

    test_writer.convert(config, image_name=image_name)


class TestZarrConverter(unittest.TestCase):
    """
    Tests methods of the ZarrConverter class
    """

    def setUp(self):
        """
        Sets up the testing environment
        """
        # io folders
        self.maxDiff = None
        self._tmp_dir = tempfile.TemporaryDirectory()
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_1"
        utils.create_folder(path_to_tiffs)
        _create_tiffs_files(path_to_tiffs)

        # Using stitching hierarchical structure for reading multichannel
        utils.create_folder(f"{self._tmp_dir.name}/tiffs_single_channel_2/x/y")
        _create_tiffs_files(f"{self._tmp_dir.name}/tiffs_single_channel_2/x/y")

        utils.create_folder(f"{self._tmp_dir.name}/converted")

        # Creating multichannel data with hierarchical structure
        utils.create_folder(f"{self._tmp_dir.name}/multichannel")
        _create_multichannel_tiff_files(f"{self._tmp_dir.name}/multichannel")

    def test_convert_to_ome_zarr(self):
        """
        Test the omezarr conversion
        """
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_2"
        converted_zarr = f"{self._tmp_dir.name}/converted"

        zarr_writer = ZarrConverter(
            path_to_tiffs, converted_zarr, {"codec": "zstd", "clevel": 1}
        )

        config = {
            "codec": "zstd",
            "clevel": 1,
            "scale_factor": [2, 2, 2],
            "pyramid_levels": 3,
        }

        zarr_writer.convert(config, image_name="test_tiffs.zarr")
        self.assertTrue(
            os.path.isdir(f"{self._tmp_dir.name}/converted/test_tiffs.zarr")
        )

    def test_pad_array_n_d(self):
        """
        Tests the pad array method
        """
        # io folders
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_1"

        zarr_writer = ZarrConverter(
            path_to_tiffs, path_to_tiffs, {"codec": "zstd", "clevel": 1}
        )

        # Reading images and padding
        array = zarr_writer.read_channel_image(path_to_tiffs)
        pad_array = zarr_writer.pad_array_n_d(array, 5)
        re_pad_array = zarr_writer.pad_array_n_d(array, 5)

        # Tests
        self.assertEqual(pad_array.ndim, 5)
        with self.assertRaises(ValueError):
            zarr_writer.pad_array_n_d(array, 6)

        self.assertEqual(re_pad_array.ndim, 5)

    @parameterized.expand(params.get_compute_pyramid_params())
    def test_compute_pyramid(self, n_lvls: int, scale_axis: int):
        """
        Tests the compute pyramid method
        """
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_1"
        zarr_writer = ZarrConverter(
            path_to_tiffs, path_to_tiffs, {"codec": "zstd", "clevel": 1}
        )
        array = zarr_writer.read_channel_image(path_to_tiffs)

        array_pyramid = zarr_writer.compute_pyramid(array, n_lvls, scale_axis)
        self.assertIsInstance(array_pyramid, list)
        self.assertEqual(len(array_pyramid), n_lvls)

        for multiscale in array_pyramid:
            self.assertIsInstance(multiscale, dask.array.core.Array)
            self.assertEqual(multiscale.ndim, 4)

    @parameterized.expand(params.get_compute_pyramid_raises_params())
    def test_compute_pyramid_raises(self, n_lvls: int, scale_axis: int):
        """
        Tests the compute pyramid method
        """
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_1"
        zarr_writer = ZarrConverter(
            path_to_tiffs, path_to_tiffs, {"codec": "zstd", "clevel": 1}
        )
        array = zarr_writer.read_channel_image(path_to_tiffs)

        with self.assertRaises(ValueError):
            zarr_writer.compute_pyramid(array, n_lvls, scale_axis)

    def _check_single_channel_omero(
        self, omero_metadata: dict, filename: PathLike
    ):
        """
        Checks the single channel omero metadata

        Parameters
        -------------
        omero_metadata: dict
            dictionary with the omero metadata from
            the OME-Zarr image

        filename: PathLike
            Path where the image is stored
        """
        expected_omero = {
            "channels": [
                {
                    "active": True,
                    "coefficient": 1,
                    "color": "000000",
                    "family": "linear",
                    "inverted": False,
                    "label": f"Channel:{filename}:0",
                    "window": {
                        "end": 1.0,
                        "max": 1.0,
                        "min": 0.0,
                        "start": 0.0,
                    },
                }
            ],
            "id": 1,
            "name": filename,
            "rdefs": {"defaultT": 0, "defaultZ": 128, "model": "color"},
            "version": "0.4",
        }

        self.assertDictEqual(omero_metadata, expected_omero)

    def _check_multiple_channel_omero(
        self, omero_metadata: dict, filename: str, channels: List[str]
    ):
        """
        Checks the multi channel omero metadata

        Parameters
        -------------
        omero_metadata: dict
            dictionary with the omero metadata from
            the OME-Zarr image

        filename: PathLike
            Path where the image is stored

        channels: List[str]
            List with channel names
        """
        channels_metadata = []

        for channel_idx in range(len(channels)):
            channels_metadata.append(
                {
                    "active": True,
                    "coefficient": 1,
                    "color": f"00000{channel_idx}",
                    "family": "linear",
                    "inverted": False,
                    "label": channels[channel_idx],
                    "window": {
                        "end": 1.0,
                        "max": 1.0,
                        "min": 0.0,
                        "start": 0.0,
                    },
                },
            )

        expected_omero = {
            "channels": channels_metadata,
            "id": 1,
            "name": filename,
            "rdefs": {"defaultT": 0, "defaultZ": 128, "model": "color"},
            "version": "0.4",
        }
        self.assertDictEqual(omero_metadata, expected_omero)

    def _check_downsamplig_metadata(self, downsampling_metadata: dict):
        """
        Checks the downsampling metadata
        """
        expected_downsampling = {
            "args": "[false]",
            "description": "Downscaling implementation based on the windowed mean of the original array",
            "kwargs": {},
            "method": "xarray_multiscale.reducers.windowed_mean",
            "version": "0.2.2",
        }
        self.assertDictEqual(downsampling_metadata, expected_downsampling)

    def _check_single_image_axes(self, axes_metadata: list):
        """
        Checks the single image axes in the
        omero metadata

        Parameters
        -----------
        axes_metadata: list
            Axes metadata in omero metadata configuration
        """
        expected_axes = [
            {"name": "t", "type": "time", "unit": "millisecond"},
            {"name": "c", "type": "channel"},
            {"name": "z", "type": "space", "unit": "micrometer"},
            {"name": "y", "type": "space", "unit": "micrometer"},
            {"name": "x", "type": "space", "unit": "micrometer"},
        ]

        self.assertIsInstance(axes_metadata, list)

        for axes_idx in range(len(expected_axes)):
            self.assertDictEqual(
                axes_metadata[axes_idx], expected_axes[axes_idx]
            )

    def _generate_single_channel_dataset_metadata(
        self, n_scaling: Optional[int] = 5
    ):
        """
        Generates a single channel dataset metadata based on
        OMERO structure

        Parameters
        -------------
        n_scaling: Optional[int]
            Scaling for each of the multiscale images
            Default: 5
        """
        datasets = []
        x_voxelsize = y_voxelsize = z_voxelsize = 1.0

        for n_scale in range(n_scaling):
            datasets.append(
                {
                    "coordinateTransformations": [
                        {
                            "scale": [
                                1.0,
                                1.0,
                                z_voxelsize,
                                z_voxelsize,
                                z_voxelsize,
                            ],
                            "type": "scale",
                        }
                    ],
                    "path": str(n_scale),
                }
            )

            x_voxelsize += x_voxelsize
            y_voxelsize += y_voxelsize
            z_voxelsize += z_voxelsize

        return datasets

    def _check_single_image_datasets(self, datasets_metadata: list):
        """
        Checks single channel image dataset metadata

        Parameters
        ------------
        datasets_metadata: list
            Metadata for each of the datasets
        """
        expected_datasets = self._generate_single_channel_dataset_metadata()

        self.assertIsInstance(datasets_metadata, list)
        for dataset_idx in range(len(datasets_metadata)):
            self.assertDictEqual(
                datasets_metadata[dataset_idx], expected_datasets[dataset_idx]
            )

    def test_check_single_channel_zarr_attributes(self):
        """
        Tests the zarr attributes of a single channel image
        """
        path_to_tiffs = f"{self._tmp_dir.name}/tiffs_single_channel_2"
        converted_zarr = f"{self._tmp_dir.name}/converted"
        filename = "test_tiffs_single_channel_2.zarr"

        _create_zarr_file(path_to_tiffs, converted_zarr, filename)

        zarr_file = zarr.open(
            f"{self._tmp_dir.name}/converted/{filename}", mode="r"
        )
        attributes = zarr_file.attrs

        # Checking axes
        self._check_single_image_axes(attributes["multiscales"][0]["axes"])

        # Checking downsampling metadata using xarray_multiscale package
        self._check_downsamplig_metadata(
            attributes["multiscales"][0]["metadata"]
        )

        # Checking datasets metadata
        self._check_single_image_datasets(
            attributes["multiscales"][0]["datasets"]
        )

        # Checking omero metadata
        self._check_single_channel_omero(attributes["omero"], filename)

    def test_check_multichannel_zarr_attributes(self):
        """
        Tests the zarr attributes of a multi channel image
        """
        path_to_tiffs = f"{self._tmp_dir.name}/multichannel"
        converted_zarr = f"{self._tmp_dir.name}/converted"
        filename = "test_multichannel.zarr"

        _create_zarr_file(path_to_tiffs, converted_zarr, filename)
        zarr_file = zarr.open(
            f"{self._tmp_dir.name}/converted/{filename}", mode="r"
        )
        attributes = zarr_file.attrs

        # Checking axes
        self._check_single_image_axes(attributes["multiscales"][0]["axes"])

        # Checking downsampling metadata using xarray_multiscale package
        self._check_downsamplig_metadata(
            attributes["multiscales"][0]["metadata"]
        )

        # Checking datasets metadata
        # TODO Include when we fix chunksizes in zarr file
        # self._check_single_image_datasets(attributes['multiscales'][0]['datasets'])

        # Checking omero metadata - channels are created if channels param is not given in converter
        # Channel:{filename}:counter
        # In setup I created a 3 channel dataset
        channels = [
            "Channel:test_multichannel.zarr:0",
            "Channel:test_multichannel.zarr:1",
            "Channel:test_multichannel.zarr:2",
            "Channel:test_multichannel.zarr:3",
        ]
        self._check_multiple_channel_omero(
            attributes["omero"], filename, channels
        )

    def tearDown(self):
        """
        Tears down the testing environment
        """
        self._tmp_dir.cleanup()
